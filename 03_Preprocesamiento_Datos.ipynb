{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulianaCarvajal/Proyecto_Deep_Learning/blob/main/03_Preprocesamiento_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías\n",
        "import requests\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "DywF-xR0wlKd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo CSV desde GitHub\n",
        "file_path = \"https://raw.githubusercontent.com/JulianaCarvajal/Proyecto_Deep_Learning/main/combined_wind_data.csv\"\n",
        "\n",
        "# Descargar el archivo desde GitHub\n",
        "response = requests.get(file_path)\n",
        "if response.status_code == 200:\n",
        "    # Leer el contenido del archivo en un DataFrame\n",
        "    data = pd.read_csv(StringIO(response.text))\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "L_-vkMZ5wuY4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna 'Date' a tipo datetime y establecer como índice\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "uhU32Ggxd_Vb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización de las Variables\n",
        "# Seleccionar columnas numéricas para normalización (excluir 'Date')\n",
        "columns_to_normalize = [col for col in data.columns if 'WS10M_MAX' in col]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])"
      ],
      "metadata": {
        "id": "MDruUfyzwvKs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar datos en características (X) y objetivo (y)\n",
        "X_scaled = data.drop(columns=['WS10M_MAX_punto6'])\n",
        "y_scaled = data['WS10M_MAX_punto6']"
      ],
      "metadata": {
        "id": "k-aYtgzbp74S"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para crear secuencias con ventanas y horizonte de pronóstico\n",
        "def create_sequences(data, target, window_size, forecast_horizon):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size - forecast_horizon + 1):\n",
        "        X.append(data[i:i + window_size])  # Ventana de entrada\n",
        "        y.append(target[i + window_size:i + window_size + forecast_horizon])  # Ventana de pronóstico\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "HrZxWqNFxJEw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de ventana y horizonte\n",
        "window_size = 30  # Días de ventana\n",
        "forecast_horizon = 7  # Días a pronosticar\n",
        "\n",
        "# Crear secuencias\n",
        "X, y = create_sequences(X_scaled, y_scaled, window_size, forecast_horizon)\n",
        "\n",
        "# División en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_-JkZOPGfs0g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmcJXK3Pr4CS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}